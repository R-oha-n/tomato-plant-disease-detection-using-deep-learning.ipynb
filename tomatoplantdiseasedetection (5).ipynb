{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11041374,"sourceType":"datasetVersion","datasetId":6877690},{"sourceId":11041562,"sourceType":"datasetVersion","datasetId":6877823}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"9480d3f8-b7e3-4d72-86ea-041c76e6a3aa","cell_type":"markdown","source":"# Tomato Plant Disease Detection Using Deep Learning - CNN","metadata":{"id":"9480d3f8-b7e3-4d72-86ea-041c76e6a3aa"}},{"id":"e8db530d-161e-4a6f-98c0-fa010fb7c5dc","cell_type":"markdown","source":"## Importing The Libraries","metadata":{"id":"e8db530d-161e-4a6f-98c0-fa010fb7c5dc"}},{"id":"ca1e7942-ad23-4ab8-a828-88900d451a9c","cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.regularizers import l1, l2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D, AveragePooling2D, MaxPooling2D, BatchNormalization\n# Various types of layers for building neural networks\nfrom tensorflow.keras.applications import DenseNet121, EfficientNetB4, Xception, VGG16, VGG19","metadata":{"id":"ca1e7942-ad23-4ab8-a828-88900d451a9c","trusted":true},"outputs":[],"execution_count":null},{"id":"190f0c1d-9815-4fbc-8b20-e4eeb8ad095a","cell_type":"markdown","source":"## Data Preprocessing","metadata":{"id":"190f0c1d-9815-4fbc-8b20-e4eeb8ad095a"}},{"id":"30d88368-2b0a-4781-8d08-83ec7ef8b5a8","cell_type":"markdown","source":"### Training Image preprocessing","metadata":{"id":"30d88368-2b0a-4781-8d08-83ec7ef8b5a8"}},{"id":"93a99e29-0b0e-414c-9e8d-79ce42c21561","cell_type":"code","source":"train_data = tf.keras.utils.image_dataset_from_directory(\n    \"/kaggle/input/tomatodiseasedleaves/tomato/train\",\n    labels=\"inferred\",\n    label_mode=\"categorical\",\n    class_names=None,\n    color_mode=\"rgb\",\n    batch_size=32,\n    image_size=(128, 128),\n    shuffle=True,\n    seed=None,\n    validation_split=None,\n    subset=None,\n    interpolation=\"bilinear\",\n    follow_links=False,\n    crop_to_aspect_ratio=False)\n\ntrain_data = train_data.map(lambda x, y: (x / 255.0, y))","metadata":{"id":"93a99e29-0b0e-414c-9e8d-79ce42c21561","trusted":true},"outputs":[],"execution_count":null},{"id":"2a000eb4-7fbb-4825-ab56-120e20d39d91","cell_type":"markdown","source":"### Validation Image Preprocessing","metadata":{"id":"2a000eb4-7fbb-4825-ab56-120e20d39d91"}},{"id":"aa090669-eff3-429c-971a-af4a7922e9dd","cell_type":"code","source":"val_data = tf.keras.preprocessing.image_dataset_from_directory(\n    \"/kaggle/input/tomatodiseasedleaves/tomato/val\",\n    labels=\"inferred\",\n    label_mode=\"categorical\",\n    class_names=None,\n    color_mode=\"rgb\",\n    batch_size=32,\n    image_size=(128, 128),\n    shuffle=True,\n    seed=None,\n    validation_split=None,\n    subset=None,\n    interpolation=\"bilinear\",\n    follow_links=False,\n    crop_to_aspect_ratio=False\n)\nval_data = val_data.map(lambda x, y: (x / 255.0, y))","metadata":{"id":"aa090669-eff3-429c-971a-af4a7922e9dd","trusted":true},"outputs":[],"execution_count":null},{"id":"aa69ed05-c581-4841-89cb-ebecf601b3e9","cell_type":"code","source":"import tensorflow as tf\n\ndef preprocess_image(image, label):\n    # Ensure image has 3 channels\n    if image.shape[-1] == 1:  # if the image is grayscale\n        image = tf.image.grayscale_to_rgb(image)\n    # Resize the image to a fixed size\n    resized_image = tf.image.resize(image, (256, 256))\n    return resized_image, label","metadata":{"id":"aa69ed05-c581-4841-89cb-ebecf601b3e9","trusted":true},"outputs":[],"execution_count":null},{"id":"ef612650-2593-4404-bca7-60c82417403e","cell_type":"markdown","source":"## Visualizing The Data","metadata":{"id":"ef612650-2593-4404-bca7-60c82417403e"}},{"id":"7f7c37e5-77f5-41c4-88b4-d93b615b0251","cell_type":"markdown","source":"### Black Mold","metadata":{"id":"7f7c37e5-77f5-41c4-88b4-d93b615b0251"}},{"id":"3648f671-868d-4cf6-970f-d05b40aa29d8","cell_type":"code","source":"path = \"/kaggle/input/tomatodiseasedleaves/tomato/train/Black mold\"\nimage_files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n\n# Display the first 6 images with their labels\nfig, axs = plt.subplots(2, 3, figsize=(10, 8))\n\nfor i in range(6):\n    image_file = image_files[i]\n    label = image_file.split('.')[0]\n\n    img_path = os.path.join(path, image_file)\n    img = mpimg.imread(img_path)\n    ax = axs[i // 3, i % 3]\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title(label)\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"3648f671-868d-4cf6-970f-d05b40aa29d8","trusted":true},"outputs":[],"execution_count":null},{"id":"52a458c6-6b17-40f5-95a4-dab0daf7ed4f","cell_type":"markdown","source":"### Gray Spot","metadata":{"id":"fca2d212-4f93-4089-8472-2985330b0859"}},{"id":"b3f0b156-7923-4a57-97dd-6a5ffddbafae","cell_type":"code","source":"path = \"/kaggle/input/tomatodiseasedleaves/tomato/train/Gray spot\"\nimage_files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n\n# Display the first 6 images with their labels\nfig, axs = plt.subplots(2, 3, figsize=(10, 8))\n\nfor i in range(6):\n    image_file = image_files[i]\n    label = image_file.split('.')[0]\n\n    img_path = os.path.join(path, image_file)\n    img = mpimg.imread(img_path)\n    ax = axs[i // 3, i % 3]\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title(label)\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"b3f0b156-7923-4a57-97dd-6a5ffddbafae","trusted":true},"outputs":[],"execution_count":null},{"id":"3b1af60c-36e1-4a06-b441-e00b92e46878","cell_type":"markdown","source":"### Powdery Mildew","metadata":{"id":"3b1af60c-36e1-4a06-b441-e00b92e46878"}},{"id":"ae938186-f4df-4979-a44d-f2cf0b526163","cell_type":"code","source":"path = \"/kaggle/input/tomatodiseasedleaves/tomato/train/powdery mildew\"\nimage_files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n\n# Display the first 6 images with their labels\nfig, axs = plt.subplots(2, 3, figsize=(10, 8))\n\nfor i in range(6):\n    image_file = image_files[i]\n    label = image_file.split('.')[0]\n\n    img_path = os.path.join(path, image_file)\n    img = mpimg.imread(img_path)\n    ax = axs[i // 3, i % 3]\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title(label)\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"ae938186-f4df-4979-a44d-f2cf0b526163","trusted":true},"outputs":[],"execution_count":null},{"id":"487abd1a-42d0-4764-8a7a-35719de525fc","cell_type":"markdown","source":"### Yellow Leaf Curl Virus","metadata":{"id":"487abd1a-42d0-4764-8a7a-35719de525fc"}},{"id":"37b486b0-682b-4cd4-922f-e832b4a26af6","cell_type":"code","source":"path = \"/kaggle/input/tomatodiseasedleaves/tomato/train/Tomato___Tomato_Yellow_Leaf_Curl_Virus\"\nimage_files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n\n# Display the first 6 images with their labels\nfig, axs = plt.subplots(2, 3, figsize=(15, 10))\n\nfor i in range(6):\n    image_file = image_files[i]\n    label = image_file.split('.')[0]\n\n    img_path = os.path.join(path, image_file)\n    img = mpimg.imread(img_path)\n    ax = axs[i // 3, i % 3]\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title(label)\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"37b486b0-682b-4cd4-922f-e832b4a26af6","trusted":true},"outputs":[],"execution_count":null},{"id":"366810c5-5ef3-4713-a0a8-742a03bf469a","cell_type":"markdown","source":"### Mosaic Virus","metadata":{"id":"366810c5-5ef3-4713-a0a8-742a03bf469a"}},{"id":"84aaed89-2010-4684-9ce8-a2c7e5bfd17d","cell_type":"code","source":"path = \"/kaggle/input/tomatodiseasedleaves/tomato/train/Tomato___Tomato_mosaic_virus\"\n\nimage_files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n\n# Display the first 6 images with their labels\nfig, axs = plt.subplots(2, 3, figsize=(15, 10))\n\nfor i in range(6):\n    image_file = image_files[i]\n    label = image_file.split('.')[0]\n\n    img_path = os.path.join(path, image_file)\n    img = mpimg.imread(img_path)\n    ax = axs[i // 3, i % 3]\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title(label)\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"84aaed89-2010-4684-9ce8-a2c7e5bfd17d","trusted":true},"outputs":[],"execution_count":null},{"id":"f62d5e3a-6d55-4fa4-8cce-5f9a0ea60243","cell_type":"markdown","source":"### Target Spots","metadata":{"id":"f62d5e3a-6d55-4fa4-8cce-5f9a0ea60243"}},{"id":"ed54bf6e-1cef-42d3-83d5-6559695973e8","cell_type":"code","source":"path = \"/kaggle/input/tomatodiseasedleaves/tomato/train/Tomato___Target_Spot\"\n\nimage_files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n\n# Display the first 6 images with their labels\nfig, axs = plt.subplots(2, 3, figsize=(15, 10))\n\nfor i in range(6):\n    image_file = image_files[i]\n    label = image_file.split('.')[0]\n\n    img_path = os.path.join(path, image_file)\n    img = mpimg.imread(img_path)\n    ax = axs[i // 3, i % 3]\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title(label)\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"ed54bf6e-1cef-42d3-83d5-6559695973e8","trusted":true},"outputs":[],"execution_count":null},{"id":"46dfd428-86a3-49c0-a10e-e657a8cc639d","cell_type":"markdown","source":"### Spider Mites Two-spotted spider mite","metadata":{"id":"46dfd428-86a3-49c0-a10e-e657a8cc639d"}},{"id":"fdb05baa-2b15-424e-959d-d716d7d9ed74","cell_type":"code","source":"path = \"/kaggle/input/tomatodiseasedleaves/tomato/train/Tomato___Spider_mites Two-spotted_spider_mite\"\n\nimage_files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n\n# Display the first 6 images with their labels\nfig, axs = plt.subplots(2, 3, figsize=(15, 10))\n\nfor i in range(6):\n    image_file = image_files[i]\n    label = image_file.split('.')[0]\n\n    img_path = os.path.join(path, image_file)\n    img = mpimg.imread(img_path)\n    ax = axs[i // 3, i % 3]\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title(label)\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"fdb05baa-2b15-424e-959d-d716d7d9ed74","trusted":true},"outputs":[],"execution_count":null},{"id":"bdcc71c2-4d13-4649-9555-f05121b40caf","cell_type":"markdown","source":"### Septoria Leaf Spot","metadata":{"id":"bdcc71c2-4d13-4649-9555-f05121b40caf"}},{"id":"fe5a65cd-95e6-4100-b059-3b9c5f4bf508","cell_type":"code","source":"path = \"/kaggle/input/tomatodiseasedleaves/tomato/train/Tomato___Septoria_leaf_spot\"\n\nimage_files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n\n# Display the first 6 images with their labels\nfig, axs = plt.subplots(2, 3, figsize=(15, 10))\n\nfor i in range(6):\n    image_file = image_files[i]\n    label = image_file.split('.')[0]\n\n    img_path = os.path.join(path, image_file)\n    img = mpimg.imread(img_path)\n    ax = axs[i // 3, i % 3]\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title(label)\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"fe5a65cd-95e6-4100-b059-3b9c5f4bf508","trusted":true},"outputs":[],"execution_count":null},{"id":"ac4412d6-b5c1-477a-941f-25ac821326b9","cell_type":"markdown","source":"### Leaf Mold","metadata":{"id":"ac4412d6-b5c1-477a-941f-25ac821326b9"}},{"id":"c9196311-0dee-4d00-ab9e-65af3677e8f8","cell_type":"code","source":"path = \"/kaggle/input/tomatodiseasedleaves/tomato/train/Tomato___Leaf_Mold\"\n\nimage_files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n\n# Display the first 6 images with their labels\nfig, axs = plt.subplots(2, 3, figsize=(15, 10))\n\nfor i in range(6):\n    image_file = image_files[i]\n    label = image_file.split('.')[0]\n\n    img_path = os.path.join(path, image_file)\n    img = mpimg.imread(img_path)\n    ax = axs[i // 3, i % 3]\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title(label)\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"c9196311-0dee-4d00-ab9e-65af3677e8f8","trusted":true},"outputs":[],"execution_count":null},{"id":"1ce0dc83-d318-4ba5-878c-3e5735aa0cd7","cell_type":"markdown","source":"### Late Blight","metadata":{"id":"1ce0dc83-d318-4ba5-878c-3e5735aa0cd7"}},{"id":"73023c25-8bc8-4e5b-8e3a-84d2eb5ea52e","cell_type":"code","source":"path = \"/kaggle/input/tomatodiseasedleaves/tomato/train/Tomato___Late_blight\"\n\nimage_files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n\n# Display the first 6 images with their labels\nfig, axs = plt.subplots(2, 3, figsize=(15, 10))\n\nfor i in range(6):\n    image_file = image_files[i]\n    label = image_file.split('.')[0]\n\n    img_path = os.path.join(path, image_file)\n    img = mpimg.imread(img_path)\n    ax = axs[i // 3, i % 3]\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title(label)\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"73023c25-8bc8-4e5b-8e3a-84d2eb5ea52e","trusted":true},"outputs":[],"execution_count":null},{"id":"3a3849ac-e239-435e-951c-4cc6ad9df4ae","cell_type":"markdown","source":"### Early Blight","metadata":{"id":"3a3849ac-e239-435e-951c-4cc6ad9df4ae"}},{"id":"cf4d1925-800a-44b1-957c-f2f334f19c9a","cell_type":"code","source":"path = \"/kaggle/input/tomatodiseasedleaves/tomato/train/Tomato___Early_blight\"\n\nimage_files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n\n# Display the first 6 images with their labels\nfig, axs = plt.subplots(2, 3, figsize=(15, 10))\n\nfor i in range(6):\n    image_file = image_files[i]\n    label = image_file.split('.')[0]\n\n    img_path = os.path.join(path, image_file)\n    img = mpimg.imread(img_path)\n    ax = axs[i // 3, i % 3]\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title(label)\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"cf4d1925-800a-44b1-957c-f2f334f19c9a","trusted":true},"outputs":[],"execution_count":null},{"id":"b18c812f-78f9-4faa-b2de-53c9db940008","cell_type":"markdown","source":"### Bacterial Spot","metadata":{"id":"b18c812f-78f9-4faa-b2de-53c9db940008"}},{"id":"c1334696-807d-4eae-83b5-ac0fd4226b50","cell_type":"code","source":"path = \"/kaggle/input/tomatodiseasedleaves/tomato/train/Tomato___Bacterial_spot\"\n\nimage_files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n\n# Display the first 6 images with their labels\nfig, axs = plt.subplots(2, 3, figsize=(15, 10))\n\nfor i in range(6):\n    image_file = image_files[i]\n    label = image_file.split('.')[0]\n\n    img_path = os.path.join(path, image_file)\n    img = mpimg.imread(img_path)\n    ax = axs[i // 3, i % 3]\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title(label)\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"c1334696-807d-4eae-83b5-ac0fd4226b50","trusted":true},"outputs":[],"execution_count":null},{"id":"97425321-fde0-4432-bf53-47643b9313b5","cell_type":"markdown","source":"### Tomato Healthy Leaves","metadata":{"id":"97425321-fde0-4432-bf53-47643b9313b5"}},{"id":"cc1430dc-dc14-456f-aa91-f09176e86e63","cell_type":"code","source":"path = \"/kaggle/input/tomatodiseasedleaves/tomato/train/Tomato___healthy\"\n\nimage_files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n\n# Display the first 6 images with their labels\nfig, axs = plt.subplots(2, 3, figsize=(15, 10))\n\nfor i in range(6):\n    image_file = image_files[i]\n    label = image_file.split('.')[0]\n\n    img_path = os.path.join(path, image_file)\n    img = mpimg.imread(img_path)\n    ax = axs[i // 3, i % 3]\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title(label)\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"cc1430dc-dc14-456f-aa91-f09176e86e63","trusted":true},"outputs":[],"execution_count":null},{"id":"96e0d30b-37c0-4d32-b793-8da25e68c690","cell_type":"markdown","source":"## Model Building\n### Creating a Layer for Resizing and Normalization\nBefore we feed our images to network, we should be resizing it to the desired size. Moreover, to improve model performance, we should normalize the image pixel value (keeping them in range 0 and 1 by dividing by 256). This should happen while training as well as inference. Hence we can add that as a layer in our Sequential Model.\n\nThis will be useful when we are done with the training and start using the model for predictions. At that time somone can supply an image that is not (256,256) and this layer will resize it","metadata":{"id":"96e0d30b-37c0-4d32-b793-8da25e68c690"}},{"id":"4f743849-8c98-441d-b166-6ab220f0c16d","cell_type":"code","source":"IMAGE_SIZE = 256\nfrom tensorflow.keras.layers import Resizing, Rescaling\nresize_and_rescale = tf.keras.Sequential([\n  Resizing(IMAGE_SIZE, IMAGE_SIZE),\n  Rescaling(1./255)\n])\n","metadata":{"id":"4f743849-8c98-441d-b166-6ab220f0c16d","trusted":true},"outputs":[],"execution_count":null},{"id":"adf19d0f-c2fb-4bcf-80db-84bef8fada52","cell_type":"markdown","source":"## Model Architecture\n### Data Augmentation\nThis boosts the accuracy of our model by augmenting the data.","metadata":{"id":"adf19d0f-c2fb-4bcf-80db-84bef8fada52"}},{"id":"c43e56d9-5b24-455b-9f7a-da8f0bdeec13","cell_type":"code","source":"from tensorflow.keras.layers import RandomFlip, RandomRotation\ndata_augmentation = tf.keras.Sequential([\n  RandomFlip(\"horizontal_and_vertical\"),\n  RandomRotation(0.2),\n])\n","metadata":{"id":"c43e56d9-5b24-455b-9f7a-da8f0bdeec13","trusted":true},"outputs":[],"execution_count":null},{"id":"98244230-b029-4c82-a401-d7ddbfcef569","cell_type":"code","source":"train_ds = train_data.map(\n    lambda x, y: (data_augmentation(x, training=True), y)\n).prefetch(buffer_size=tf.data.AUTOTUNE)","metadata":{"id":"98244230-b029-4c82-a401-d7ddbfcef569","trusted":true},"outputs":[],"execution_count":null},{"id":"7dccdc32-da2c-40b6-aa92-63b15c02c5ed","cell_type":"code","source":"import tensorflow as tf\n\n# Resize function\ndef resize_images(image, label):\n    image = tf.image.resize(image, [256, 256])  # Resize to 256x256\n    return image, label\n\n# Apply resizing to your dataset\ntrain_data = train_data.map(resize_images)\nval_data = val_data.map(resize_images)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"83b9c8c9-33ed-4bec-ab27-2f7486a35ea9","cell_type":"markdown","source":"### Adding L2-Regularization","metadata":{}},{"id":"c84c81e8-0303-49d5-8755-522142519ff7","cell_type":"code","source":"from tensorflow.keras import models, layers\nfrom tensorflow.keras.layers import Input\n\nBATCH_SIZE = 32\nIMAGE_SIZE = 256\nCHANNELS = 3\nn_classes = 13\n\ninput_shape = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\nmodel = models.Sequential([\n    Input(shape=input_shape),\n    resize_and_rescale,\n    layers.Conv2D(32, kernel_size = (3,3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Flatten(),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(n_classes, activation='softmax'),\n])\n","metadata":{"id":"c84c81e8-0303-49d5-8755-522142519ff7","trusted":true},"outputs":[],"execution_count":null},{"id":"967c280c-4c8c-439c-ae0a-e7db7bf9e9e4","cell_type":"code","source":"conv_base = DenseNet121(\n    weights='imagenet',\n    include_top = False,\n    input_shape=(256,256,3),\n    pooling='avg'\n)","metadata":{"id":"967c280c-4c8c-439c-ae0a-e7db7bf9e9e4","trusted":true},"outputs":[],"execution_count":null},{"id":"6ac038cb-9672-45b4-a14e-156028cd22f3","cell_type":"code","source":"conv_base.trainable = False","metadata":{"id":"6ac038cb-9672-45b4-a14e-156028cd22f3","trusted":true},"outputs":[],"execution_count":null},{"id":"e129236d-b32d-4826-9fd9-5337b3255066","cell_type":"code","source":"model = Sequential()\nmodel.add(conv_base)\nmodel.add(BatchNormalization())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.35))\nmodel.add(BatchNormalization())\nmodel.add(Dense(120, activation='relu'))\nmodel.add(Dense(13, activation='softmax'))","metadata":{"id":"e129236d-b32d-4826-9fd9-5337b3255066","trusted":true},"outputs":[],"execution_count":null},{"id":"6a1690a3-a9a4-4ee4-bfc0-2734ef45cbb0","cell_type":"markdown","source":"## Compiling the Model\nWe use adam Optimizer, SparseCategoricalCrossentropy for losses, accuracy as a metric","metadata":{}},{"id":"492ca918-66c5-40b3-b532-fc35b12b9b22","cell_type":"code","source":"model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"id":"492ca918-66c5-40b3-b532-fc35b12b9b22","trusted":true},"outputs":[],"execution_count":null},{"id":"4c740ec1-67c2-4f17-ad0d-99a5cd4799e0","cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport random\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# ✅ 1. Set a fixed seed for reproducibility\nSEED = 42\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\n\n# ✅ 2. Define callbacks for stability\nearly_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)  \ncheckpoint_callback = ModelCheckpoint(\"best_model.keras\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\", verbose=1)\n\n# ✅ 3. Train the model with controlled randomness\nhistory = model.fit(\n    train_data,\n    epochs=100,\n    validation_data=val_data,\n    callbacks=[early_stopping, checkpoint_callback]\n)\n\n# ✅ 4. Load the best saved model for stable evaluation\nmodel = tf.keras.models.load_model(\"best_model.keras\")","metadata":{"id":"4c740ec1-67c2-4f17-ad0d-99a5cd4799e0","trusted":true},"outputs":[],"execution_count":null},{"id":"c6150648-ce59-41df-89dc-6fc9ce99c33f","cell_type":"code","source":"evaluation = model.evaluate(val_data)\n\n# Print the evaluation metrics\nprint(\"Validation Loss:\", evaluation[0])\nprint(\"Validation Accuracy:\", evaluation[1])","metadata":{"id":"c6150648-ce59-41df-89dc-6fc9ce99c33f","trusted":true},"outputs":[],"execution_count":null},{"id":"be806e15-030f-4b1c-b6d0-e33be31620bc","cell_type":"markdown","source":"## Graphical Feature Representation","metadata":{}},{"id":"a0f9b965-2b25-4ddd-b763-f6bb31177a3c","cell_type":"code","source":"# Plot training & validation accuracy values\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\n\n# Plot training & validation loss values\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{"id":"a0f9b965-2b25-4ddd-b763-f6bb31177a3c","trusted":true},"outputs":[],"execution_count":null},{"id":"2cfd890f-e544-4c9f-856e-a2705eecea4c","cell_type":"markdown","source":"**You can see above that we get 96.55% accuracy for our test dataset. This is considered to be a good accuracy**","metadata":{}},{"id":"be05b24f-d9ef-4354-92ea-032ee573f438","cell_type":"markdown","source":"## Results and Findings","metadata":{}},{"id":"fed04b2d-96f6-44ba-a7bb-92711fb0b127","cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\n\n# Manually define class names (update this with actual class names)\nclass_names = ['Black mold', 'Gray spot', 'Tomato__Bacterial_spot', 'Tomato__Early_blight', 'Tomato__Late_blight', \n               'Tomato__Leaf_Mold', 'Tomato__Septoria_leaf_spot', 'Tomato__Spider_mites Two-spotted_spider_mite', 'Tomato__Target_Spot', 'Tomato__Tomato_Yellow_Leaf_Curl_Virus', \n               'Tomato__healthy', 'powdery mildew', 'Tomato__Tomato_mosaic_virus']  # Modify based on your dataset\n\n# Make predictions on the validation set\nval_images = []\nval_labels = []\nval_predictions = []\n\nfor images, labels in val_data:\n    preds = model.predict(images)\n    val_images.extend(images)\n    val_labels.extend(labels)\n    val_predictions.extend(preds)\n\nval_images = np.array(val_images)\nval_labels = np.argmax(np.array(val_labels), axis=1)\nval_predictions = np.argmax(np.array(val_predictions), axis=1)","metadata":{"id":"fed04b2d-96f6-44ba-a7bb-92711fb0b127","trusted":true},"outputs":[],"execution_count":null},{"id":"637293bf-87ff-4431-a8c1-6e5352e9cb37","cell_type":"code","source":"# Generate a classification report\nreport = classification_report(val_labels, val_predictions, target_names=class_names)\nprint(report)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ba6ae525-3735-4377-8847-fadab3f9cd9a","cell_type":"code","source":"conf_matrix = confusion_matrix(val_labels, val_predictions)\nplt.figure(figsize=(10, 8))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6b7dd98b-5599-49c7-8543-6a302969e676","cell_type":"markdown","source":"# END","metadata":{}}]}